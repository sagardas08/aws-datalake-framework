AWSTemplateFormatVersion: "2010-09-09"

Parameters:
  LambdaIamRole:
    Type: String
    Default: arn:aws:iam::315119964270:role/dl-fmwrk-lambda-role
  Environment:
    Type: String
    Default: prod
  CodeBucket:
    Type: String
    Default: dl-fmwrk-code-us-east-2
  TargetBucket:
    Type: String
    Default: dl-fmwrk-code-us-east-2
Resources:
  Zipper:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: zipper
      Architectures:
        - x86_64
      Handler: index.lambda_handler
      Runtime: python3.7
      Timeout: 10
      Role: !Ref LambdaIamRole
      Environment:
        Variables:
          code_bucket: !Ref CodeBucket
          target_bucket: !Ref TargetBucket
          env: !Ref Environment
      Code:
        ZipFile: |
          import boto3
          import os
          import shutil
          import cfnresponse

          s3 = boto3.resource("s3")


          def download_s3_folder(bucket_name, s3_folder, local_dir=None):
              """
              Download the contents of a folder directory
              Args:
                  bucket_name: the name of the s3 bucket
                  s3_folder: the folder path in the s3 bucket
                  local_dir: a relative or absolute directory path in the local file system
              """
              bucket = s3.Bucket(bucket_name)
              for obj in bucket.objects.filter(Prefix=s3_folder):
                  target = obj.key if local_dir is None \
                      else os.path.join(local_dir, os.path.relpath(obj.key, s3_folder))
                  if not os.path.exists(os.path.dirname(target)):
                      os.makedirs(os.path.dirname(target))
                  if obj.key[-1] == '/':
                      continue
                  bucket.download_file(obj.key, target)


          def zipper(name, src, src_key, tgt, tgt_key=None):
              """
              Download, zip and upload the contents of a folder directory
              Args:
                  name: the name of the zip file (without extension)
                  src: source bucket
                  src_key: path of the source file
                  tgt: target bucket
                  tgt_key: path of the target
              """
              # download the files into tmp/zip/ folder
              download_s3_folder(src, src_key, f"/tmp/zip/{name}/")
              # zip the contents of tmp/zip/ folder
              shutil.make_archive(base_name=f"/tmp/{name}",
                                  format="zip", root_dir="/tmp/zip/")
              print(f"zipped in /tmp/ folder as {name}.zip")
              # once zipped in temp copy it to your preferred s3 location
              if tgt_key:
                  s3.Object(tgt, f"{tgt_key}/{name}.zip").delete()
                  s3.meta.client.upload_file(
                      f"/tmp/{name}.zip", tgt, f"{tgt_key}/{name}.zip")
                  print(f"uploaded to {tgt}/{tgt_key} as {name}.zip")
                  res = f"{tgt}/{tgt_key}/{name}.zip"
              else:
                  s3.Object(tgt, f"{name}.zip").delete()
                  s3.meta.client.upload_file(
                      f"/tmp/{name}.zip", tgt, f"{name}.zip")
                  print(f"uploaded to {tgt} as {name}.zip")
                  res = f"{tgt}/{name}.zip"
              dir = '/tmp/'
              for files in os.listdir(dir):
                  path = os.path.join(dir, files)
                  try:
                      shutil.rmtree(path)
                  except OSError:
                      os.remove(path)
              return res

          def lambda_handler(event, context):
              code_bucket = os.environ['code_bucket']
              target_bucket = os.environ['target_bucket']
              env = os.environ['env']
              target_key = f"{env}/aws-datalake-framework/dependencies"
              dl_dict = {
                  "connector": f"{env}/aws-datalake-framework/connector/",
                  "utils": f"{env}/aws-datalake-framework/src/utils/"
              }
              body = {"status": 200, "uploaded_files": []}
              for obj in dl_dict:
                  try:
                      response = zipper(
                          src=code_bucket,
                          src_key=dl_dict[obj],
                          tgt=target_bucket,
                          name=obj,
                          tgt_key=target_key
                      )
                      body["uploaded_files"].append(response)
                  except Exception as e:
                      print(f"failed to zip and upload {obj} from {dl_dict[obj]}")
                      print(str(e))
                      if "failed" in body.keys():
                          body["failed"].append(f"{dl_dict[obj]}/{obj}.zip")
                      else:
                          body["failed"] = [f"{dl_dict[obj]}/{obj}.zip"]
                      body["status"] = 404
                      break
              if body["status"] == 200:
                cfnresponse.send(event, context, cfnresponse.SUCCESS, body, "CustomResourcePhysicalID")
              else:
                cfnresponse.send(event, context, cfnresponse.FAILED, body, "CustomResourcePhysicalID")

  ZipperInvoke:
    Type: AWS::CloudFormation::CustomResource
    Version: "1.0"
    Properties:
      ServiceToken: !GetAtt Zipper.Arn
